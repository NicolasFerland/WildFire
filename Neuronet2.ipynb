{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, concatenate, Input, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "modelList = []\n",
    "history = []\n",
    "xaxis = []  \n",
    "refit_history = []\n",
    "refit_xaxis = []\n",
    "    \n",
    "import time\n",
    "import keras\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.start = time.time()\n",
    "    #def on_epoch_begin(self, batch, logs={}):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.start)\n",
    "        \n",
    "from keras.callbacks import Callback\n",
    "class TimedStopping(Callback):\n",
    "    '''Stop training when enough time has passed.\n",
    "    # Arguments\n",
    "        seconds: maximum time before stopping.\n",
    "        verbose: verbosity mode.\n",
    "    '''\n",
    "    def __init__(self, seconds=None, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.start_time = 0\n",
    "        self.seconds = seconds\n",
    "        self.verbose = verbose\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if time.time() - self.start_time > self.seconds:\n",
    "            self.model.stop_training = True\n",
    "            if self.verbose:\n",
    "                print('Stopping after %s seconds.' % self.seconds)\n",
    "                \n",
    "def Plot(i, text = 'acc', label = ''):\n",
    "    plt.plot(xaxis[i], history[i].history['val_'+text], label = label)\n",
    "def Plot2(i, j, text = 'acc', label = ''):\n",
    "    plt.plot(xaxis[i]+[t+xaxis[i][-1] for t in refit_xaxis[j]]\n",
    "             , history[i].history['val_'+text]+refit_history[j].history['val_'+text], label = label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Already done, do not do again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weatherData = np.concatenate((np.load('weatherData1991.npy'),np.load('FullweatherData.npy'),np.load('weatherData2000_04.npy'),\n",
    "                             np.load('weatherData2005_09.npy'),np.load('weatherData2010_15.npy')))\n",
    "df = (pd.DataFrame(np.load('NewFireData.npy'), columns=['day', 'lat', 'lon', 'num_cause', 'tarray', 'xybinarray', 'fire'])\n",
    "      .drop('num_cause',axis=1).astype(int, copy=False))\n",
    "\n",
    "def moddf(df):\n",
    "    df0 = df.drop(['tarray', 'xybinarray'],axis=1).values\n",
    "    df0 = (df0-df0.mean())/ df0.std()\n",
    "    \n",
    "    tarray = df['tarray'].values\n",
    "    xybinarray = df['xybinarray'].values\n",
    "    df1 = np.empty((len(df),31,4))\n",
    "    for i in range(0,31):\n",
    "        for j in range(0,4):\n",
    "            df1[:,i,j] = weatherData[tarray-i, xybinarray,j]\n",
    "    # Normalize features\n",
    "    df1 = (df1-df1.mean())/ df1.std()\n",
    "    \n",
    "    return df0, df1\n",
    "\n",
    "xdf = df.drop('fire',axis=1)\n",
    "y = df['fire'].values\n",
    "x0, x1 = moddf(xdf)\n",
    "X0, X0_test, X1, X1_test, y, y_test = train_test_split(\n",
    "    x0, x1, y, test_size=0.1, shuffle=True)\n",
    "X0_train, X0_val, X1_train, X1_val, y_train, y_val = train_test_split(\n",
    "    X0, X1, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "np.save('X0_train', X0_train, allow_pickle=True, fix_imports=False)\n",
    "np.save('X1_train', X1_train, allow_pickle=True, fix_imports=False)\n",
    "np.save('y_train', y_train, allow_pickle=True, fix_imports=False)\n",
    "np.save('X0_val', X0_val, allow_pickle=True, fix_imports=False)\n",
    "np.save('X1_val', X1_val, allow_pickle=True, fix_imports=False)\n",
    "np.save('y_val', y_val, allow_pickle=True, fix_imports=False)\n",
    "np.save('X0_test', X0_test, allow_pickle=True, fix_imports=False)\n",
    "np.save('X1_test', X1_test, allow_pickle=True, fix_imports=False)\n",
    "np.save('y_test', y_test, allow_pickle=True, fix_imports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train neuronet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0_train = np.load('X0_train.npy', mmap_mode='r')\n",
    "X1_train = np.load('X1_train.npy', mmap_mode='r')\n",
    "y_train = np.load('y_train.npy', mmap_mode='r')\n",
    "X0_val = np.load('X0_val.npy')\n",
    "X1_val = np.load('X1_val.npy')\n",
    "y_val = np.load('y_val.npy')\n",
    "X0_test = np.load('X0_test.npy')\n",
    "X1_test = np.load('X1_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_train = 2973745\n",
    "indices = np.arange(length_train, dtype=int)\n",
    "\n",
    "def generator(batchSize=512):\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        for i in range(0, len(indices), batchSize):\n",
    "            batch_indices = indices[i:i+batchSize]\n",
    "            batch_indices.sort()\n",
    "\n",
    "            bx0 = X0_train[batch_indices,...]\n",
    "            bx1 = X1_train[batch_indices,...]\n",
    "            by = y_train[batch_indices,...]\n",
    "\n",
    "            yield ([bx0,bx1], by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(nUnits, batchSize, timelimit, nlayer):\n",
    "    x0 = Input(shape=(3,)) # location\n",
    "    x1 = Input(shape=(31,4)) # weather\n",
    "    # first\n",
    "    inistate = Dense(nUnits, activation = 'relu')(x0)\n",
    "    x = GRU(nUnits, return_sequences=True)(x1, initial_state = inistate) \n",
    "    # nlayer middle layers\n",
    "    for _ in range(nlayer): \n",
    "        inistate = Dense(nUnits, activation = 'relu')(inistate)\n",
    "        x = GRU(nUnits, return_sequences=True)(x, initial_state = inistate) \n",
    "    # last\n",
    "    inistate = Dense(nUnits, activation = 'relu')(inistate)\n",
    "    x = GRU(nUnits, return_sequences=False)(x, initial_state = inistate) \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[x0,x1], outputs=x)\n",
    "    time_callback = TimeHistory()\n",
    "    timed_stopping = TimedStopping(timelimit)\n",
    "    model.compile(optimizer='adam', metrics=['acc'],\n",
    "                  loss='binary_crossentropy')\n",
    "    history.append(model.fit_generator(generator(batchSize),steps_per_epoch = 2973745//batchSize\n",
    "                                        ,epochs=100, verbose=2, \n",
    "              validation_data=([X0_val,X1_val], y_val),callbacks=[time_callback, timed_stopping]))\n",
    "    xaxis.append(time_callback.times)\n",
    "    modelList.append(model) \n",
    "    \n",
    "def refit(batchsize, timelimit, model):\n",
    "    time_callback = TimeHistory()\n",
    "    timed_stopping = TimedStopping(timelimit)\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0., patience=10)\n",
    "    refit_history.append(model.fit_generator(generator(batchSize),steps_per_epoch = 2973745//batchSize\n",
    "                                        ,epochs=200, batch_size=batchsize,verbose=2, shuffle=True, \n",
    "              validation_data=([X0_val,X1_val], y_val),callbacks=[time_callback, timed_stopping, es]))\n",
    "    refit_xaxis.append(time_callback.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5045s - loss: 0.6269 - acc: 0.6348 - val_loss: 0.6086 - val_acc: 0.6635\n"
     ]
    }
   ],
   "source": [
    "fit(nUnits = 80, batchSize = 1024, timelimit = 300, nlayer = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the accuracy is very low after 5045 s (1.4 hours).\n",
    "\n",
    "With less fires, I had an accuracy of 71% after 4000 s. Correlation in time might be useful and now it's harder to learn them because it's on more years.\n",
    "\n",
    "Hopefully, it'll get better with more epochs.\n",
    "\n",
    "Python is using 2.6 GB right now even with the generator. I should look what makes the memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !!! Already done\n",
    "\n",
    "modelList[0].save('my_model5045.h5')\n",
    "# try save weight in case saving model doesn't work\n",
    "modelList[0].save_weights('my_model_weights5045.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer gru_13 expects 1 inputs, but it received 2 input tensors. Input received: [<tf.Tensor 'input_10:0' shape=(?, 31, 4) dtype=float32>, <tf.Tensor 'dense_17/Relu:0' shape=(?, 80) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-616f88763232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model5045.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    305\u001b[0m                         \u001b[1;34m'Maybe you meant to use '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     52\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    137\u001b[0m                 return cls.from_config(config['config'],\n\u001b[0;32m    138\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[1;32m--> 139\u001b[1;33m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2449\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2450\u001b[1;33m             \u001b[0mprocess_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2452\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[1;34m(layer_data)\u001b[0m\n\u001b[0;32m   2445\u001b[0m                         \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2447\u001b[1;33m                         \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2449\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# modify the input spec to include the state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRecurrent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    437\u001b[0m                              \u001b[1;34m'but it received '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                              \u001b[1;34m' input tensors. Input received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                              str(inputs))\n\u001b[0m\u001b[0;32m    440\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer gru_13 expects 1 inputs, but it received 2 input tensors. Input received: [<tf.Tensor 'input_10:0' shape=(?, 31, 4) dtype=float32>, <tf.Tensor 'dense_17/Relu:0' shape=(?, 80) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model5045.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1328s - loss: 0.6020 - acc: 0.6695 - val_loss: 0.5962 - val_acc: 0.6770\n",
      "Epoch 2/100\n",
      "582s - loss: 0.5928 - acc: 0.6782 - val_loss: 0.5904 - val_acc: 0.6811\n",
      "Epoch 3/100\n",
      "583s - loss: 0.5891 - acc: 0.6809 - val_loss: 0.5891 - val_acc: 0.6817\n",
      "Epoch 4/100\n",
      "582s - loss: 0.5866 - acc: 0.6830 - val_loss: 0.5867 - val_acc: 0.6826\n",
      "Epoch 5/100\n",
      "581s - loss: 0.5846 - acc: 0.6844 - val_loss: 0.5878 - val_acc: 0.6816\n",
      "Epoch 6/100\n",
      "581s - loss: 0.5830 - acc: 0.6855 - val_loss: 0.5834 - val_acc: 0.6855\n",
      "Epoch 7/100\n",
      "584s - loss: 0.5814 - acc: 0.6869 - val_loss: 0.5821 - val_acc: 0.6861\n",
      "Epoch 8/100\n",
      "582s - loss: 0.5798 - acc: 0.6879 - val_loss: 0.5832 - val_acc: 0.6860\n",
      "Epoch 9/100\n",
      "581s - loss: 0.5786 - acc: 0.6887 - val_loss: 0.5837 - val_acc: 0.6845\n",
      "Epoch 10/100\n",
      "583s - loss: 0.5773 - acc: 0.6898 - val_loss: 0.5801 - val_acc: 0.6871\n",
      "Epoch 11/100\n",
      "583s - loss: 0.5762 - acc: 0.6905 - val_loss: 0.5795 - val_acc: 0.6886\n",
      "Epoch 12/100\n",
      "585s - loss: 0.5749 - acc: 0.6916 - val_loss: 0.5782 - val_acc: 0.6892\n",
      "Epoch 13/100\n",
      "581s - loss: 0.5739 - acc: 0.6921 - val_loss: 0.5784 - val_acc: 0.6892\n",
      "Epoch 14/100\n",
      "582s - loss: 0.5730 - acc: 0.6928 - val_loss: 0.5813 - val_acc: 0.6872\n",
      "Epoch 15/100\n",
      "581s - loss: 0.5721 - acc: 0.6935 - val_loss: 0.5784 - val_acc: 0.6897\n",
      "Epoch 16/100\n",
      "584s - loss: 0.5710 - acc: 0.6942 - val_loss: 0.5780 - val_acc: 0.6895\n",
      "Epoch 17/100\n",
      "583s - loss: 0.5703 - acc: 0.6947 - val_loss: 0.5762 - val_acc: 0.6908\n",
      "Epoch 18/100\n",
      "580s - loss: 0.5696 - acc: 0.6952 - val_loss: 0.5761 - val_acc: 0.6908\n",
      "Epoch 19/100\n",
      "580s - loss: 0.5686 - acc: 0.6960 - val_loss: 0.5753 - val_acc: 0.6914\n",
      "Epoch 20/100\n",
      "582s - loss: 0.5679 - acc: 0.6966 - val_loss: 0.5768 - val_acc: 0.6898\n",
      "Epoch 21/100\n",
      "583s - loss: 0.5672 - acc: 0.6968 - val_loss: 0.5756 - val_acc: 0.6915\n",
      "Epoch 22/100\n",
      "583s - loss: 0.5665 - acc: 0.6974 - val_loss: 0.5755 - val_acc: 0.6921\n",
      "Epoch 23/100\n",
      "577s - loss: 0.5660 - acc: 0.6978 - val_loss: 0.5769 - val_acc: 0.6911\n",
      "Epoch 24/100\n",
      "575s - loss: 0.5653 - acc: 0.6984 - val_loss: 0.5768 - val_acc: 0.6907\n"
     ]
    }
   ],
   "source": [
    "# In case it doesn't work\n",
    "def fit_loadweight(nUnits, batchSize, timelimit, nlayer):\n",
    "    x0 = Input(shape=(3,)) # location\n",
    "    x1 = Input(shape=(31,4)) # weather\n",
    "    # first\n",
    "    inistate = Dense(nUnits, activation = 'relu')(x0)\n",
    "    x = GRU(nUnits, return_sequences=True)(x1, initial_state = inistate) \n",
    "    # nlayer middle layers\n",
    "    for _ in range(nlayer): \n",
    "        inistate = Dense(nUnits, activation = 'relu')(inistate)\n",
    "        x = GRU(nUnits, return_sequences=True)(x, initial_state = inistate) \n",
    "    # last\n",
    "    inistate = Dense(nUnits, activation = 'relu')(inistate)\n",
    "    x = GRU(nUnits, return_sequences=False)(x, initial_state = inistate) \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[x0,x1], outputs=x)\n",
    "    model.load_weights('my_model_weights5045.h5')\n",
    "    time_callback = TimeHistory()\n",
    "    timed_stopping = TimedStopping(timelimit)\n",
    "    model.compile(optimizer='adam', metrics=['acc'],\n",
    "                  loss='binary_crossentropy')\n",
    "    history.append(model.fit_generator(generator(batchSize),steps_per_epoch = 2973745//batchSize\n",
    "                                        ,epochs=100, verbose=2, \n",
    "              validation_data=([X0_val,X1_val], y_val),callbacks=[time_callback, timed_stopping]))\n",
    "    xaxis.append(time_callback.times)\n",
    "    modelList.append(model)\n",
    "    \n",
    "fit_loadweight(nUnits = 80, batchSize = 1024, timelimit = 4*3600, nlayer = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The 5045s for the 1st epoch was probably inacurate. Most likely my computer went to sleep during the calculation.\n",
    "\n",
    "However, the accuracy is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28c40a04710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/P/fEd7bxysmnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28c40a043c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot(0, 'acc', '80, 1')\n",
    "plt.legend()\n",
    "\n",
    "# It is still going up so we could improve it by training longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelList[0].save_weights('my_model_weights14k.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowgpu]",
   "language": "python",
   "name": "conda-env-tensorflowgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
